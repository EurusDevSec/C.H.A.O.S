# ğŸ“… Sprint 1 Guide: The Foundation
**Chá»§ Ä‘á»:** XÃ¢y Dá»±ng Háº¡ Táº§ng Container (Infrastructure Layer)
**Tráº¡ng thÃ¡i:** ğŸš€ Ready to Start

---

## 1. Má»¥c TiÃªu (Objectives)
Má»¥c tiÃªu cá»§a Sprint nÃ y lÃ  xÃ¢y dá»±ng "bá»™ khung" vá»¯ng cháº¯c cho dá»± Ã¡n C.H.A.O.S. Káº¿t thÃºc Sprint 1, báº¡n cáº§n cÃ³ má»™t cá»¥m Cluster cháº¡y trÃªn Local (Docker) mÆ°á»£t mÃ , khÃ´ng ngá»‘n quÃ¡ nhiá»u RAM.

*   âœ… **Services:** Spark (Master/Worker), Kafka (KRaft mode), MinIO, Portainer.
*   âœ… **Constraint:** Tá»•ng lÆ°á»£ng RAM tiÃªu thá»¥ < 8GB (Ä‘á»ƒ chá»«a chá»— cho OS vÃ  trÃ¬nh duyá»‡t).
*   âœ… **Outcome:** Lá»‡nh `docker-compose up -d` kÃ­ch hoáº¡t thÃ nh cÃ´ng táº¥t cáº£ services.

---

## 2. Chuáº©n Bá»‹ (Prerequisites)

### 2.1. Cáº¥u TrÃºc ThÆ° Má»¥c
Táº¡o cáº¥u trÃºc thÆ° má»¥c dá»± Ã¡n nhÆ° sau:

```bash
C.H.A.O.S/
â”œâ”€â”€ data/               # Chá»©a dá»¯ liá»‡u thÃ´ (náº¿u táº£i vá» local)
â”œâ”€â”€ docker-compose.yaml # File Ä‘á»‹nh nghÄ©a toÃ n bá»™ háº¡ táº§ng
â”œâ”€â”€ jobs/               # Chá»©a code Spark Job (Ingestion, Processing)
â”œâ”€â”€ notebooks/          # Chá»©a Jupyter Notebooks (Analysis/EDA)
â”œâ”€â”€ schemas/            # Chá»©a Ä‘á»‹nh nghÄ©a Schema (náº¿u cáº§n)
â””â”€â”€ services/           # Chá»©a code cÃ¡c microservices (API, Dashboard)
```

### 2.2. CÃ´ng Cá»¥
*   Docker Desktop (Ä‘Ã£ báº­t Kubernetes hoáº·c khÃ´ng, tÃ¹y chá»n - khuyáº¿n khÃ­ch táº¯t K8s Ä‘á»ƒ nháº¹ mÃ¡y).
*   VS Code.

---

## 3. CÃ¡c BÆ°á»›c Thá»±c Hiá»‡n (Implementation Steps)

### BÆ°á»›c 1: Táº¡o file `docker-compose.yaml`
ÄÃ¢y lÃ  bÆ°á»›c quan trá»ng nháº¥t. HÃ£y táº¡o file `docker-compose.yaml` táº¡i thÆ° má»¥c gá»‘c vá»›i ná»™i dung tham kháº£o sau (Ä‘Ã£ tá»‘i Æ°u KRaft vÃ  Portainer):

```yaml
version: '3.8'

services:
  # --- Visualization & Monitoring ---
  portainer:
    image: portainer/portainer-ce:latest
    container_name: chaos_portainer
    ports:
      - "9000:9000"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - portainer_data:/data
    restart: always

  # --- Message Queue (Kafka KRaft Mode - No Zookeeper) ---
  kafka:
    image: bitnami/kafka:latest
    container_name: chaos_kafka
    ports:
      - "9092:9092"
    environment:
      # KRaft settings
      - KAFKA_CFG_NODE_ID=0
      - KAFKA_CFG_PROCESS_ROLES=controller,broker
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka:9093
      # Listeners
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
    volumes:
      - kafka_data:/bitnami/kafka
    start_period: 30s  # Äá»£i á»•n Ä‘á»‹nh
    restart: on-failure

  # --- Storage (MinIO - Data Lake) ---
  minio:
    image: minio/minio:latest
    container_name: chaos_minio
    ports:
      - "9000:9000" # API Port
      - "9001:9001" # Console Port
    environment:
      - MINIO_ROOT_USER=admin
      - MINIO_ROOT_PASSWORD=password123
    command: server /data --console-address ":9001"
    volumes:
      - minio_data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  # --- Processing (Spark) ---
  spark-master:
    image: bitnami/spark:latest
    container_name: chaos_spark_master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - "8080:8080"
      - "7077:7077"
    volumes:
      - ./jobs:/opt/bitnami/spark/jobs # Mount code vÃ o container

  spark-worker:
    image: bitnami/spark:latest
    container_name: chaos_spark_worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G # Giá»›i háº¡n RAM Worker
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    depends_on:
      - spark-master
    volumes:
      - ./jobs:/opt/bitnami/spark/jobs

volumes:
  kafka_data:
  minio_data:
  portainer_data:
```

### BÆ°á»›c 2: Start Services & Kiá»ƒm Tra Láº§n Äáº§u
Má»Ÿ terminal táº¡i thÆ° má»¥c dá»± Ã¡n vÃ  cháº¡y:

```bash
docker-compose up -d
```

â³ **Chá» khoáº£ng 1-2 phÃºt** Ä‘á»ƒ cÃ¡c service khá»Ÿi Ä‘á»™ng hoÃ n toÃ n.

### BÆ°á»›c 3: Smoke Test (Kiá»ƒm tra sá»‘ng cÃ²n)
Truy cáº­p cÃ¡c Ä‘á»‹a chá»‰ sau trÃªn trÃ¬nh duyá»‡t Ä‘á»ƒ Ä‘áº£m báº£o má»i thá»© Ä‘Ã£ "lÃªn Ä‘Ã¨n":

1.  **Portainer (Quáº£n lÃ½ Container):**
    *   URL: `http://localhost:9000`
    *   HÃ nh Ä‘á»™ng: Táº¡o tÃ i khoáº£n admin láº§n Ä‘áº§u. Chá»n mÃ´i trÆ°á»ng "Local". Kiá»ƒm tra xem cÃ³ 5 container Ä‘ang cháº¡y (green state) khÃ´ng.
2.  **MinIO (Data Lake):**
    *   URL: `http://localhost:9001`
    *   Login: `admin` / `password123`.
    *   HÃ nh Ä‘á»™ng: Thá»­ táº¡o má»™t Bucket tÃªn lÃ  `climate-data`.
3.  **Spark Master:**
    *   URL: `http://localhost:8080`
    *   HÃ nh Ä‘á»™ng: Kiá»ƒm tra xem cÃ³ 1 Worker Ä‘ang status `ALIVE` khÃ´ng.

### BÆ°á»›c 4: Clean Up (Optional)
Náº¿u muá»‘n táº¯t há»‡ thá»‘ng Ä‘á»ƒ nghá»‰ ngÆ¡i:
```bash
docker-compose down
# Hoáº·c gá»¡ bá» cáº£ volumes (xÃ³a sáº¡ch dá»¯ liá»‡u)
docker-compose down -v
```

---

## 4. Troubleshooting (Gá»¡ Rá»‘i)

*   **Lá»—i: Port already in use**:
    *   NguyÃªn nhÃ¢n: CÃ³ service khÃ¡c (nhÆ° IIS, Skype, hoáº·c project cÅ©) Ä‘ang chiáº¿m port 8080 hoáº·c 9000.
    *   Kháº¯c phá»¥c: Äá»•i port mapping trong `docker-compose.yaml`. VÃ­ dá»¥ Ä‘á»•i Spark UI thÃ nh `8081:8080`.
*   **Lá»—i: Kafka Crashed (Exited 1)**:
    *   NguyÃªn nhÃ¢n: ThÆ°á»ng do thiáº¿u ID node.
    *   Kháº¯c phá»¥c: Äáº£m báº£o biáº¿n `KAFKA_CFG_NODE_ID` Ä‘Ã£ Ä‘Æ°á»£c set. Náº¿u váº«n lá»—i, thá»­ xÃ³a volume `docker-compose down -v` vÃ  cháº¡y láº¡i.
*   **MÃ¡y quÃ¡ lag**:
    *   Kháº¯c phá»¥c: Giáº£m `SPARK_WORKER_MEMORY` xuá»‘ng `1G` hoáº·c táº¯t bá»›t trÃ¬nh duyá»‡t Chrome.

---

ğŸš€ **ChÃºc báº¡n hoÃ n thÃ nh Sprint 1 tá»‘t Ä‘áº¹p!**
